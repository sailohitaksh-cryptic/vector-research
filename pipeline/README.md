# VectorInsight Dashboard

Automated data pipeline and interactive dashboard for mosquito surveillance and vector control analytics.

## ğŸ“‹ Overview

VectorInsight pulls data from the VectorCam API, processes entomological surveillance data, calculates key metrics, and presents them in an interactive web-based dashboard for public health decision-making.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VectorCam API  â”‚â”€â”€â”€â”€â–¶â”‚  Data Pipeline   â”‚â”€â”€â”€â”€â–¶â”‚   Dashboard     â”‚
â”‚  (surveillance  â”‚     â”‚  â€¢ Extract       â”‚     â”‚  (Streamlit)    â”‚
â”‚   & specimens)  â”‚     â”‚  â€¢ Clean         â”‚     â”‚  â€¢ Interactive  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â€¢ Calculate     â”‚     â”‚  â€¢ Filterable   â”‚
                        â”‚  â€¢ Store         â”‚     â”‚  â€¢ Exportable   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Data Storage    â”‚
                        â”‚  â€¢ Parquet       â”‚
                        â”‚  â€¢ SQLite        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
vectorinsight_pipeline/
â”œâ”€â”€ config.py                     # Configuration management
â”œâ”€â”€ pipeline.py                   # Main orchestration script
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env.example                  # Environment variables template
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ data_extraction.py        # API data fetching
â”‚   â”œâ”€â”€ data_processing.py        # Data cleaning & transformation
â”‚   â”œâ”€â”€ metrics_calculator.py     # Metric calculations
â”‚   â””â”€â”€ database.py               # SQLite operations
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                    # Streamlit dashboard
â”‚   â””â”€â”€ components/               # Dashboard components (future)
â””â”€â”€ data/
    â”œâ”€â”€ raw/                      # Monthly Parquet snapshots
    â”œâ”€â”€ logs/                     # Pipeline execution logs
    â””â”€â”€ vectorinsight.db          # SQLite database
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone or navigate to the project directory
cd vectorinsight_pipeline

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Create a `.env` file from the template:

```bash
cp .env.example .env
```

Edit `.env` and add your API credentials:

```
API_SECRET_KEY=your-actual-api-key-here
```

### 3. Run the Pipeline

```bash
# Run pipeline (pulls data from API)
python pipeline.py

# Or run with existing data (skip API call)
python pipeline.py --skip-extraction
```

### 4. Launch Dashboard

```bash
# Start the dashboard
streamlit run dashboard/app.py
```

The dashboard will open in your browser at `http://localhost:8501`

## ğŸ“Š Dashboard Features

### Default Metrics (Always Visible)
1. **Collections Timeline** - Temporal trends of field collections
2. **Species Composition** - Pie and bar charts of mosquito species
3. **Indoor Resting Density** - Mosquitoes per house from PSC data
4. **Blood-Feeding Rates** - Fed vs unfed mosquitoes
5. **LLIN Usage** - Bed net coverage and usage rates
6. **IRS Coverage** - Indoor residual spraying coverage

### Interactive Filters
- **Date Range** - Select custom time periods
- **Geographic** - Filter by district/site
- **Collection Method** - PSC, HLC, CDC Light Trap, etc.
- **Species** - Focus on specific mosquito species

### Tabs & Visualizations
- ğŸ“ˆ **Temporal Trends** - Time series of collections and specimens
- ğŸ¦Ÿ **Species Composition** - Detailed species breakdowns
- ğŸ  **Indoor Density** - PSC-based resting density metrics
- ğŸ›¡ï¸ **Interventions** - LLIN and IRS coverage analysis
- ğŸ”¬ **Collection Methods** - Method comparison and efficiency
- ğŸ“ **Geographic Distribution** - Site/district comparisons

## ğŸ“ˆ Key Metrics Calculated

### Temporal Metrics
- Collections by month/quarter/year
- Specimens by month/quarter/year
- Seasonal trends

### Species Metrics
- Total specimens by species
- Anopheles vs other mosquitoes
- Species groups (gambiae complex, funestus group, etc.)
- Sex ratios
- Species by collection method

### Collection Method Metrics
- Collections by method
- Specimens per collection by method
- Method efficiency comparison

### Intervention Metrics
- IRS coverage rate (% of households)
- LLIN availability per household
- LLIN usage rate (% of people sleeping under nets)
- LLIN types distribution (Pyrethroid, PBO, Chlorfenapyr)

### Blood-Feeding Metrics
- Feeding status (Fed, Unfed, Half Gravid, Gravid)
- Feeding rates by species
- Blood-feeding patterns over time

### Indoor Resting Density (PSC)
- Average mosquitoes per house
- Average Anopheles per house
- Density trends over time
- Density by district

### Geographic Metrics
- Collections by district/site
- Species distribution by location
- Intervention coverage by location

## ğŸ—„ï¸ Data Storage

### Parquet Files (Raw Data Archive)
- `data/raw/surveillance_YYYY_MM.parquet` - Monthly snapshots
- `data/raw/specimens_YYYY_MM.parquet` - Monthly snapshots
- Timestamped backups for audit trail

### SQLite Database (Processed Data)
- `surveillance_sessions` - Collection session details
- `specimens` - Individual mosquito specimens
- `monthly_metrics` - Pre-calculated aggregations

### Benefits of Hybrid Approach
âœ… Historical tracking with monthly snapshots  
âœ… Fast queries with indexed database  
âœ… Easy migration to AWS (S3 + RDS/Athena)  
âœ… Audit trail with timestamped backups  

## ğŸ”§ Pipeline Operations

### Manual Execution
```bash
# Full pipeline with API pull
python pipeline.py

# Use existing data (testing/development)
python pipeline.py --skip-extraction
```

### Scheduled Execution (Future)
```bash
# Using cron (Linux/Mac)
0 1 1 * * cd /path/to/vectorinsight_pipeline && python pipeline.py

# Using Task Scheduler (Windows)
# Create task to run pipeline.py on 1st of each month
```

### Pipeline Steps
1. **Extract** - Pull data from VectorCam API
2. **Clean** - Handle missing values, standardize formats
3. **Transform** - Add derived fields, categorize data
4. **Store** - Save to Parquet and SQLite
5. **Calculate** - Compute all metrics
6. **Report** - Generate summary report

## ğŸ“ Logging

Logs are saved in `data/logs/`:
- `pipeline_YYYYMMDD_HHMMSS.log` - Pipeline execution logs
- `summary_report_YYYYMMDD_HHMMSS.txt` - Summary statistics

## ğŸ” Security & Configuration

### Environment Variables
Store sensitive data in `.env` file (NOT in git):
- `API_SECRET_KEY` - VectorCam API authentication
- `DB_PATH` - Database file location
- `RAW_DATA_DIR` - Raw data storage location

### Data Security
- API key stored securely in `.env`
- Add `.env` to `.gitignore`
- Consider encrypting sensitive data at rest

## ğŸš€ AWS Migration Path

### Current (Local)
```
Local Machine
â”œâ”€â”€ Python Scripts
â”œâ”€â”€ SQLite Database
â””â”€â”€ Parquet Files
```

### Future (AWS)
```
AWS Cloud
â”œâ”€â”€ Lambda/ECS (Pipeline)
â”œâ”€â”€ RDS/Aurora (Database)
â”œâ”€â”€ S3 (Data Lake)
â”œâ”€â”€ Fargate/EC2 (Dashboard)
â””â”€â”€ EventBridge (Scheduling)
```

### Migration Steps
1. **Data Storage**: SQLite â†’ RDS PostgreSQL
2. **Files**: Local Parquet â†’ S3 buckets
3. **Pipeline**: Python script â†’ Lambda/ECS Task
4. **Scheduling**: Manual â†’ EventBridge
5. **Dashboard**: Local Streamlit â†’ Fargate/EC2
6. **Access**: Single user â†’ Load Balancer + Auth

## ğŸ”® Future Enhancements

### Phase 1 (Current)
âœ… Data extraction from API  
âœ… Data cleaning and processing  
âœ… Metrics calculation  
âœ… Interactive dashboard  
âœ… Filtering and exploration  

### Phase 2 (Near-term)
- [ ] PRISM integration (epi, climate data)
- [ ] Automated scheduling
- [ ] Email notifications
- [ ] Data quality alerts
- [ ] Export to Excel/PDF

### Phase 3 (Future)
- [ ] Natural language query interface (LLM)
- [ ] Predictive analytics
- [ ] Insecticide resistance module
- [ ] Mobile-responsive design
- [ ] Multi-user access control

## ğŸ› Troubleshooting

### "API_SECRET_KEY not configured"
**Solution**: Create `.env` file with your API key

### "No data available" in dashboard
**Solution**: Run `python pipeline.py` first to populate database

### "Database locked" error
**Solution**: Close dashboard before running pipeline, or use PostgreSQL for concurrent access

### Slow dashboard loading
**Solution**: Reduce date range filter or limit data returned

### Import errors
**Solution**: Install all dependencies: `pip install -r requirements.txt`

## ğŸ“ Support

For questions about:
- **Backend/API**: Contact backend team
- **Metrics/Public Health**: Contact public health team
- **Technical Issues**: Check logs in `data/logs/`

## ğŸ“„ License

[Your License Here]

## ğŸ‘¥ Contributors

- Data Pipeline Development: [Your Name]
- Public Health Requirements: Neil & Team
- Backend API: Backend Team

---

**Last Updated**: October 2025  
**Version**: 1.0.0
